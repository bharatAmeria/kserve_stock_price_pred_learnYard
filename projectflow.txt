1. Create repo, clone it in local

2. Create a virtual environment -> python3 -m venv .venv

3. Activate the virtual environment -> source venv/bin/Activate

4. Create template.py file and copy code and run it ( it create a project structure ready for you )

5. Add code to setup.py, project.toml, testEnvironment.py, requirements.txt, src/constants/__init__.py.
    Now run testEnvironment.py (verifies the pyhton environment and install dependecies from requirements.txt)

6. add code to src folder, config.yaml.

7. create .env file and add 
    AWS_ACCESS_KEY_ID=
    AWS_SECRET_ACCESS_KEY=
    AWS_S3_BUCKET_NAME=
    AWS_DEFAULT_REGION=
    DATASET_URI=https://drive.google.com/file/d/17nz2lVYeLqbCWDuZb2h2gpROe5BJOe2K/view?usp=sharing

8. Now SignIn in your aws google console create an IAM user and give administrator access.
    Download AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_DEFAULT_REGION.

    Add these credentials to .env file.


9. Now do { aws configure }. It takes AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_DEFAULT_REGION as input.

10. Now create s3 bucket.  
    aws s3 mb s3://learnyard-data-ingestion --region eu-north-1

    Add bucket name in the .env file AWS_S3_BUCKET_NAME

11. Now run src/main.py file to check each component is working properly.
    (Delete the file store in the s3 directory. So that your s3 bucket charge is less.)
    ( In the file .gitignore add files below 
      artifacts/*
      istio-1.19.0
      .venv
    )

12. Now create a directory under name app where we define our fastAPI app. Copy code files in the directory.
    Create and .env file in the app directory and paste below credentials.

    S3_BUCKET_NAME=learnyard-data-ingestion
    AWS_DEFAULT_REGION=eu-north-1
    MODEL_S3_KEY = "models/model.pkl"

13. Now create a cluster to configure kserve and kubeflow
    create eks cluster for kubeflow 
    prerequsite (install eksctl, In this case it is preinstalled) 

    eksctl create cluster \
      --name kubeflow-cluster \
      --version 1.27 \
      --region eu-north-1 \
      --nodegroup-name standard-workers \
      --node-type t3.large \
      --nodes 3 \
      --managed

      (Take a break. it will take around 15 mins. Or you can implement step 14 and 15)


14. Build our Docker image of our src folder and push to ECR.
    (Do step 16 First to save time. Because configure cluster takes around 20 min. )

    (   Why ? -> Because our kubeflow pipeline need docker image to communicate with in order to run pipeline.
             Or 
             We can define each component in the file of kubeflow_pipeline.py which is not best practice.
    )
    (Copy .dockerignore file and paste in your repo.)
    a. Create an ECR repo where we push our image -> aws ecr create-repository --repository-name kubeflow_pipeline
    b. Now go on AWS console and seacrh for ECR.
    c. Check ECR repo is created or not.
    d. Now move in the repo and On the top right click on the  icon named (view oush command)
       (This helps you to login in your private repo and push the images in repo)
    e. Follow command step by step.
    f. Once the image is pushed to ecr repo. Copy the name of image and paste it file kubeflow/kube_flow_pipeline.py under name 
       BASE_IMAGE constant
       (This is not a good Prcatice to hard code your image url.
        You can store it in your.env file and load it in file but for the tutorial/learning POV.
        We are hard coding in the file.
       )

15. Now build Docker image for our fastApi app.
    
    a. Create an ECR repo where we push our image -> aws ecr create-repository --repository-name fastapi-inference
    b. Move to directory app/ -> cd app
    c. Follow the steps from the STEP 13. (point c)
    d. Now create and InferenceService.yaml file in the root directory
    e. In place of container/image : replace the image name to your pushed docker image link.
       (here also we are hard code our image url. You can store it as Kube-secret. If you want to improve security)

-------------------------------------------------------------
Once the cluster is ready. Now we need to setup kubeflow.

a. Go to "https://www.kubeflow.org/docs/components/pipelines/legacy-v1/installation/localcluster-deployment/"
b. From bash terminal run below command:
---
first run this -> export PIPELINE_VERSION=2.4.0
Then run below 3 at once ->
kubectl apply -k "github.com/kubeflow/pipelines/manifests/kustomize/cluster-scoped-resources?ref=$PIPELINE_VERSION"
kubectl wait --for condition=established --timeout=60s crd/applications.app.k8s.io
kubectl apply -k "github.com/kubeflow/pipelines/manifests/kustomize/env/platform-agnostic?ref=$PIPELINE_VERSION"
---

c. Check services status -> kubectl get all -n kubeflow (depending on your system, it'll take finally around 15-20min to get them all working)
or you can also run -> kubectl get pod -A

---
Move ahead if you see all services running ->

(kbf) PS C:\Users\Personal\Documents\kubeflow-practice-proj> kubectl get all -n kubeflow
NAME                                                  READY   STATUS    RESTARTS      AGE
pod/cache-deployer-deployment-86d88fd8-c5dd8          1/1     Running   0             29m
pod/cache-server-699d6d4b58-c9zqx                     1/1     Running   0             29m
pod/metadata-envoy-deployment-946867bf-tgz59          1/1     Running   0             29m
pod/metadata-grpc-deployment-6c44975f56-pnrbt         1/1     Running   8 (15m ago)   29m
pod/metadata-writer-844c8c496d-nx56x                  1/1     Running   0             29m
pod/minio-5d5574b5cd-f4kxc                            1/1     Running   0             29m
pod/ml-pipeline-7b8c745b88-x524c                      1/1     Running   5 (14m ago)   29m
pod/ml-pipeline-persistenceagent-9cdb8686b-7z6jx      1/1     Running   3 (15m ago)   29m
pod/ml-pipeline-scheduledworkflow-bcfc5899-5tnwg      1/1     Running   0             29m
pod/ml-pipeline-ui-585dfd5955-nnrmt                   1/1     Running   0             29m
pod/ml-pipeline-viewer-crd-cbb68b94-pxkm8             1/1     Running   0             29m
pod/ml-pipeline-visualizationserver-55c694986-psvhg   1/1     Running   0             29m
pod/mysql-85fd58798-vw9l5                             1/1     Running   0             29m
pod/workflow-controller-7bc7b46bfd-nchx9              1/1     Running   0             29m
---

9. Access the UI (run on a separate terminal) -> kubectl port-forward -n kubeflow svc/ml-pipeline-ui 8080:80

10. Now, open a new terminal, activate the venv and run -> python kubeflow_pipeline.py (this will create a yaml file that we'll use to deploy on kf cluster)

11. Now run -> kfp pipeline create -p IrisProject kubeflow_pipeline.yaml

12. Now go back to UI and check the pipeline, you can now choose to create a run.

-------------------------------------------------------------------------------
 Setup KServe :

1. Install kserver on your cluster -> curl -s "https://raw.githubusercontent.com/kserve/kserve/release-0.12/hack/quick_install.sh" | bash

2. Deploy the InferenceService:-> kubectl apply -f InferenceService.yaml

3. Check the deployment:-> 
    # Check the InferenceService status
    kubectl get inferenceservice fastapi-serve

    # Check pods
    kubectl get pods -l serving.kserve.io/inferenceservice=fastapi-serve

    # Check logs
    kubectl logs -l serving.kserve.io/inferenceservice=fastapi-serve

4. Getting the KServe URL:

4.1. Get the InferenceService URL: 
    # Get the URL
    kubectl get inferenceservice fastapi-serve -o jsonpath='{.status.url}'

    # Or check status
    kubectl describe inferenceservice fastapi-serve

4.2. Using port-forward for testing
kubectl port-forward svc/fastapi-serve-predictor-00001-private 8080:80

# Then access:
  http://localhost:8080
  http://localhost:8080/v1/models/fastapi-serve:predict

4.3. Hit the url using terminal:
    curl -v http://localhost:8080/v1/models/fastapi-serve:predict \
   -H "Content-Type: application/json" \
   -d '{"instances": [[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]]}'


























 
      
 