apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: fastapi-serve
  namespace: default  # Add namespace if needed
spec:
  predictor:
    containers:
    - name: fastapi-container
      image: bharat9838/fastapi-app:latest
      
      ports:
      - containerPort: 8000
        name: http1
        protocol: TCP
      resources:
        requests:
          cpu: 100m
          memory: 512Mi
        limits:
          cpu: 1000m
          memory: 2Gi
      readinessProbe:
        httpGet:
          path: /health
          port: 8000
        initialDelaySeconds: 10
        periodSeconds: 5
      livenessProbe:
        httpGet:
          path: /health
          port: 8000
        initialDelaySeconds: 30
        periodSeconds: 10